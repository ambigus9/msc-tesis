{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_df(df, metrics):\n",
    "    import numpy as np\n",
    "    \n",
    "    df_temp = df.copy()\n",
    "\n",
    "    table = pd.pivot_table(df_temp, values=metrics, index=['arquitectura'],\n",
    "                        columns=['iteracion'], aggfunc=[np.mean])\n",
    "\n",
    "    df_mean = round(table*100,2)\n",
    "    \n",
    "    table = pd.pivot_table(df_temp, values=metrics, index=['arquitectura'],\n",
    "                        columns=['iteracion'], aggfunc=[np.std])\n",
    "\n",
    "    df_std = round(table*100,2)\n",
    "    \n",
    "    table = pd.pivot_table(df_temp, values=metrics, index=['arquitectura'],\n",
    "                        columns=['iteracion'], aggfunc=[np.mean, np.std])\n",
    "\n",
    "    df_dataset = round(table*100,2)\n",
    "    return df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_latex(df, metrics, kfold_ok=True):\n",
    "    archs = df.index.values\n",
    "    iteracion_range = range(5)\n",
    "\n",
    "    for arch in archs:\n",
    "        pairs = []\n",
    "        for iteracion in iteracion_range:\n",
    "            for metric in metrics:\n",
    "                mean_val = df[\"mean\"][metric][iteracion][arch]\n",
    "                if kfold_ok:\n",
    "                    std_val = df[\"std\"][metric][iteracion][arch]\n",
    "                    pairs.append(str(mean_val)+\" \"+\"$\"+\"\\\\\"+\"pm\"+\"{\"+str(std_val)+\"}\"+\"$\")\n",
    "                else:\n",
    "                    pairs.append(str(mean_val))\n",
    "        latex_line = \" & \".join(pairs)\n",
    "        latex_line = \"\\multicolumn{1}{|l|}{\"+ arch +\"} & \" +  latex_line + \" \" + \"\\\\\" +\"\\\\\" +\" \"+ \"\\\\\" + \"hline\"\n",
    "        \n",
    "        print(f\"{arch}\")\n",
    "        print(\"\\n\")\n",
    "        print(latex_line)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_by_pathologist(pathologist):\n",
    "    if pathologist == 1:\n",
    "        metrics = [\"test1_accu\", \"test1_f1score\", \"test1_recall\"]\n",
    "    elif pathologist == 2:\n",
    "        metrics = [\"test2_accu\", \"test2_f1score\", \"test2_recall\"]\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HARDVAR - PATHOLOGIST 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kfold</th>\n",
       "      <th>iteracion</th>\n",
       "      <th>arquitectura</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accu</th>\n",
       "      <th>test1_loss</th>\n",
       "      <th>test1_accu</th>\n",
       "      <th>test1_precision</th>\n",
       "      <th>test1_recall</th>\n",
       "      <th>test1_f1score</th>\n",
       "      <th>test2_loss</th>\n",
       "      <th>test2_accu</th>\n",
       "      <th>test2_precision</th>\n",
       "      <th>test2_recall</th>\n",
       "      <th>test2_f1score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>0.522397</td>\n",
       "      <td>0.730511</td>\n",
       "      <td>0.567843</td>\n",
       "      <td>0.709491</td>\n",
       "      <td>0.717242</td>\n",
       "      <td>0.709491</td>\n",
       "      <td>0.702322</td>\n",
       "      <td>0.595368</td>\n",
       "      <td>0.700810</td>\n",
       "      <td>0.746138</td>\n",
       "      <td>0.700810</td>\n",
       "      <td>0.716534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Xception</td>\n",
       "      <td>0.499213</td>\n",
       "      <td>0.756048</td>\n",
       "      <td>0.540164</td>\n",
       "      <td>0.718171</td>\n",
       "      <td>0.718921</td>\n",
       "      <td>0.718171</td>\n",
       "      <td>0.715732</td>\n",
       "      <td>0.590423</td>\n",
       "      <td>0.684028</td>\n",
       "      <td>0.759933</td>\n",
       "      <td>0.684028</td>\n",
       "      <td>0.705289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DenseNet169</td>\n",
       "      <td>0.559061</td>\n",
       "      <td>0.696909</td>\n",
       "      <td>0.580255</td>\n",
       "      <td>0.682292</td>\n",
       "      <td>0.692519</td>\n",
       "      <td>0.682292</td>\n",
       "      <td>0.671300</td>\n",
       "      <td>0.535179</td>\n",
       "      <td>0.716435</td>\n",
       "      <td>0.748557</td>\n",
       "      <td>0.716435</td>\n",
       "      <td>0.728526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>InceptionV4</td>\n",
       "      <td>0.526662</td>\n",
       "      <td>0.726479</td>\n",
       "      <td>0.559266</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.710778</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.704251</td>\n",
       "      <td>0.566231</td>\n",
       "      <td>0.697338</td>\n",
       "      <td>0.760340</td>\n",
       "      <td>0.697338</td>\n",
       "      <td>0.716289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DenseNet121</td>\n",
       "      <td>0.566669</td>\n",
       "      <td>0.744624</td>\n",
       "      <td>0.575830</td>\n",
       "      <td>0.740451</td>\n",
       "      <td>0.753322</td>\n",
       "      <td>0.740451</td>\n",
       "      <td>0.733121</td>\n",
       "      <td>0.523628</td>\n",
       "      <td>0.753762</td>\n",
       "      <td>0.790647</td>\n",
       "      <td>0.753762</td>\n",
       "      <td>0.765838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>co-train1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.735243</td>\n",
       "      <td>0.745126</td>\n",
       "      <td>0.735243</td>\n",
       "      <td>0.728735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>co-train2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732350</td>\n",
       "      <td>0.775521</td>\n",
       "      <td>0.732350</td>\n",
       "      <td>0.746442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>0.473966</td>\n",
       "      <td>0.769489</td>\n",
       "      <td>0.550157</td>\n",
       "      <td>0.730035</td>\n",
       "      <td>0.742586</td>\n",
       "      <td>0.730035</td>\n",
       "      <td>0.722122</td>\n",
       "      <td>0.532528</td>\n",
       "      <td>0.736979</td>\n",
       "      <td>0.773750</td>\n",
       "      <td>0.736979</td>\n",
       "      <td>0.749599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Xception</td>\n",
       "      <td>0.508900</td>\n",
       "      <td>0.751344</td>\n",
       "      <td>0.563566</td>\n",
       "      <td>0.704861</td>\n",
       "      <td>0.713185</td>\n",
       "      <td>0.704861</td>\n",
       "      <td>0.704822</td>\n",
       "      <td>0.675446</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.774817</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.638468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>DenseNet169</td>\n",
       "      <td>0.526339</td>\n",
       "      <td>0.717742</td>\n",
       "      <td>0.552728</td>\n",
       "      <td>0.717593</td>\n",
       "      <td>0.726861</td>\n",
       "      <td>0.717593</td>\n",
       "      <td>0.710229</td>\n",
       "      <td>0.544363</td>\n",
       "      <td>0.728009</td>\n",
       "      <td>0.769490</td>\n",
       "      <td>0.728009</td>\n",
       "      <td>0.741932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>InceptionV4</td>\n",
       "      <td>0.748703</td>\n",
       "      <td>0.733199</td>\n",
       "      <td>0.747231</td>\n",
       "      <td>0.737558</td>\n",
       "      <td>0.737291</td>\n",
       "      <td>0.737558</td>\n",
       "      <td>0.737372</td>\n",
       "      <td>0.947563</td>\n",
       "      <td>0.692419</td>\n",
       "      <td>0.798457</td>\n",
       "      <td>0.692419</td>\n",
       "      <td>0.714944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>DenseNet121</td>\n",
       "      <td>0.628504</td>\n",
       "      <td>0.727823</td>\n",
       "      <td>0.623558</td>\n",
       "      <td>0.726273</td>\n",
       "      <td>0.743096</td>\n",
       "      <td>0.726273</td>\n",
       "      <td>0.716413</td>\n",
       "      <td>0.512850</td>\n",
       "      <td>0.762731</td>\n",
       "      <td>0.790353</td>\n",
       "      <td>0.762731</td>\n",
       "      <td>0.772501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>co-train1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.748264</td>\n",
       "      <td>0.748032</td>\n",
       "      <td>0.748264</td>\n",
       "      <td>0.747437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>co-train2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.707176</td>\n",
       "      <td>0.799070</td>\n",
       "      <td>0.707176</td>\n",
       "      <td>0.728125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>0.494110</td>\n",
       "      <td>0.741263</td>\n",
       "      <td>0.525381</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.734159</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.733280</td>\n",
       "      <td>0.629182</td>\n",
       "      <td>0.686921</td>\n",
       "      <td>0.776595</td>\n",
       "      <td>0.686921</td>\n",
       "      <td>0.709126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Xception</td>\n",
       "      <td>0.508038</td>\n",
       "      <td>0.743280</td>\n",
       "      <td>0.541066</td>\n",
       "      <td>0.720775</td>\n",
       "      <td>0.720946</td>\n",
       "      <td>0.720775</td>\n",
       "      <td>0.718938</td>\n",
       "      <td>0.581900</td>\n",
       "      <td>0.695891</td>\n",
       "      <td>0.776791</td>\n",
       "      <td>0.695891</td>\n",
       "      <td>0.716875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>DenseNet169</td>\n",
       "      <td>0.720527</td>\n",
       "      <td>0.698253</td>\n",
       "      <td>0.653575</td>\n",
       "      <td>0.730324</td>\n",
       "      <td>0.739481</td>\n",
       "      <td>0.730324</td>\n",
       "      <td>0.723827</td>\n",
       "      <td>0.587720</td>\n",
       "      <td>0.750579</td>\n",
       "      <td>0.793094</td>\n",
       "      <td>0.750579</td>\n",
       "      <td>0.763829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>InceptionV4</td>\n",
       "      <td>0.556849</td>\n",
       "      <td>0.717070</td>\n",
       "      <td>0.569146</td>\n",
       "      <td>0.711227</td>\n",
       "      <td>0.711992</td>\n",
       "      <td>0.711227</td>\n",
       "      <td>0.708553</td>\n",
       "      <td>0.593593</td>\n",
       "      <td>0.689815</td>\n",
       "      <td>0.763799</td>\n",
       "      <td>0.689815</td>\n",
       "      <td>0.710528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>DenseNet121</td>\n",
       "      <td>0.577595</td>\n",
       "      <td>0.746640</td>\n",
       "      <td>0.595283</td>\n",
       "      <td>0.731771</td>\n",
       "      <td>0.737406</td>\n",
       "      <td>0.731771</td>\n",
       "      <td>0.726935</td>\n",
       "      <td>0.539941</td>\n",
       "      <td>0.747975</td>\n",
       "      <td>0.799916</td>\n",
       "      <td>0.747975</td>\n",
       "      <td>0.762821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>co-train1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742766</td>\n",
       "      <td>0.745195</td>\n",
       "      <td>0.742766</td>\n",
       "      <td>0.739942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>co-train2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725405</td>\n",
       "      <td>0.792808</td>\n",
       "      <td>0.725405</td>\n",
       "      <td>0.743335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>0.754385</td>\n",
       "      <td>0.710349</td>\n",
       "      <td>0.696673</td>\n",
       "      <td>0.725984</td>\n",
       "      <td>0.728127</td>\n",
       "      <td>0.725984</td>\n",
       "      <td>0.726360</td>\n",
       "      <td>0.949686</td>\n",
       "      <td>0.657697</td>\n",
       "      <td>0.790010</td>\n",
       "      <td>0.657697</td>\n",
       "      <td>0.682917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Xception</td>\n",
       "      <td>0.543845</td>\n",
       "      <td>0.718414</td>\n",
       "      <td>0.568819</td>\n",
       "      <td>0.694155</td>\n",
       "      <td>0.694252</td>\n",
       "      <td>0.694155</td>\n",
       "      <td>0.694201</td>\n",
       "      <td>0.633485</td>\n",
       "      <td>0.639178</td>\n",
       "      <td>0.753503</td>\n",
       "      <td>0.639178</td>\n",
       "      <td>0.665756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>DenseNet169</td>\n",
       "      <td>0.554147</td>\n",
       "      <td>0.728495</td>\n",
       "      <td>0.574311</td>\n",
       "      <td>0.711806</td>\n",
       "      <td>0.726705</td>\n",
       "      <td>0.711806</td>\n",
       "      <td>0.701425</td>\n",
       "      <td>0.514338</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.765441</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.746977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>InceptionV4</td>\n",
       "      <td>0.759834</td>\n",
       "      <td>0.715726</td>\n",
       "      <td>0.701141</td>\n",
       "      <td>0.736400</td>\n",
       "      <td>0.736537</td>\n",
       "      <td>0.736400</td>\n",
       "      <td>0.736461</td>\n",
       "      <td>0.949705</td>\n",
       "      <td>0.679688</td>\n",
       "      <td>0.793434</td>\n",
       "      <td>0.679688</td>\n",
       "      <td>0.703292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>DenseNet121</td>\n",
       "      <td>0.554981</td>\n",
       "      <td>0.756048</td>\n",
       "      <td>0.571259</td>\n",
       "      <td>0.731192</td>\n",
       "      <td>0.739877</td>\n",
       "      <td>0.731192</td>\n",
       "      <td>0.724949</td>\n",
       "      <td>0.568348</td>\n",
       "      <td>0.743924</td>\n",
       "      <td>0.788136</td>\n",
       "      <td>0.743924</td>\n",
       "      <td>0.757743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>co-train1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.734978</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.724124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>co-train2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731481</td>\n",
       "      <td>0.783652</td>\n",
       "      <td>0.731481</td>\n",
       "      <td>0.747151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>0.807665</td>\n",
       "      <td>0.702957</td>\n",
       "      <td>0.753912</td>\n",
       "      <td>0.719329</td>\n",
       "      <td>0.721383</td>\n",
       "      <td>0.719329</td>\n",
       "      <td>0.715963</td>\n",
       "      <td>0.779337</td>\n",
       "      <td>0.706597</td>\n",
       "      <td>0.773067</td>\n",
       "      <td>0.706597</td>\n",
       "      <td>0.725494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Xception</td>\n",
       "      <td>0.506234</td>\n",
       "      <td>0.752016</td>\n",
       "      <td>0.552964</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708813</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708512</td>\n",
       "      <td>0.643923</td>\n",
       "      <td>0.638310</td>\n",
       "      <td>0.757041</td>\n",
       "      <td>0.638310</td>\n",
       "      <td>0.665011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>DenseNet169</td>\n",
       "      <td>0.621653</td>\n",
       "      <td>0.724462</td>\n",
       "      <td>0.596714</td>\n",
       "      <td>0.731771</td>\n",
       "      <td>0.731436</td>\n",
       "      <td>0.731771</td>\n",
       "      <td>0.730813</td>\n",
       "      <td>0.657055</td>\n",
       "      <td>0.709201</td>\n",
       "      <td>0.799798</td>\n",
       "      <td>0.709201</td>\n",
       "      <td>0.729945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>InceptionV4</td>\n",
       "      <td>0.716354</td>\n",
       "      <td>0.740591</td>\n",
       "      <td>0.722031</td>\n",
       "      <td>0.748843</td>\n",
       "      <td>0.752431</td>\n",
       "      <td>0.748843</td>\n",
       "      <td>0.749188</td>\n",
       "      <td>1.028757</td>\n",
       "      <td>0.662616</td>\n",
       "      <td>0.803920</td>\n",
       "      <td>0.662616</td>\n",
       "      <td>0.687294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>DenseNet121</td>\n",
       "      <td>0.605177</td>\n",
       "      <td>0.736559</td>\n",
       "      <td>0.606573</td>\n",
       "      <td>0.732639</td>\n",
       "      <td>0.742492</td>\n",
       "      <td>0.732639</td>\n",
       "      <td>0.725988</td>\n",
       "      <td>0.561124</td>\n",
       "      <td>0.747106</td>\n",
       "      <td>0.788805</td>\n",
       "      <td>0.747106</td>\n",
       "      <td>0.760349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>co-train1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.749132</td>\n",
       "      <td>0.748795</td>\n",
       "      <td>0.749132</td>\n",
       "      <td>0.748528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>co-train2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.694734</td>\n",
       "      <td>0.791200</td>\n",
       "      <td>0.694734</td>\n",
       "      <td>0.716762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    kfold  iteracion arquitectura  val_loss  val_accu  test1_loss  test1_accu  \\\n",
       "0       0          0     ResNet50  0.522397  0.730511    0.567843    0.709491   \n",
       "1       0          0     Xception  0.499213  0.756048    0.540164    0.718171   \n",
       "2       0          0  DenseNet169  0.559061  0.696909    0.580255    0.682292   \n",
       "3       0          0  InceptionV4  0.526662  0.726479    0.559266    0.708333   \n",
       "4       0          0  DenseNet121  0.566669  0.744624    0.575830    0.740451   \n",
       "5       0          0    co-train1       NaN       NaN         NaN    0.735243   \n",
       "6       0          0    co-train2       NaN       NaN         NaN    0.732350   \n",
       "7       0          1     ResNet50  0.473966  0.769489    0.550157    0.730035   \n",
       "8       0          1     Xception  0.508900  0.751344    0.563566    0.704861   \n",
       "9       0          1  DenseNet169  0.526339  0.717742    0.552728    0.717593   \n",
       "10      0          1  InceptionV4  0.748703  0.733199    0.747231    0.737558   \n",
       "11      0          1  DenseNet121  0.628504  0.727823    0.623558    0.726273   \n",
       "12      0          1    co-train1       NaN       NaN         NaN    0.748264   \n",
       "13      0          1    co-train2       NaN       NaN         NaN    0.707176   \n",
       "14      0          2     ResNet50  0.494110  0.741263    0.525381    0.734375   \n",
       "15      0          2     Xception  0.508038  0.743280    0.541066    0.720775   \n",
       "16      0          2  DenseNet169  0.720527  0.698253    0.653575    0.730324   \n",
       "17      0          2  InceptionV4  0.556849  0.717070    0.569146    0.711227   \n",
       "18      0          2  DenseNet121  0.577595  0.746640    0.595283    0.731771   \n",
       "19      0          2    co-train1       NaN       NaN         NaN    0.742766   \n",
       "20      0          2    co-train2       NaN       NaN         NaN    0.725405   \n",
       "21      0          3     ResNet50  0.754385  0.710349    0.696673    0.725984   \n",
       "22      0          3     Xception  0.543845  0.718414    0.568819    0.694155   \n",
       "23      0          3  DenseNet169  0.554147  0.728495    0.574311    0.711806   \n",
       "24      0          3  InceptionV4  0.759834  0.715726    0.701141    0.736400   \n",
       "25      0          3  DenseNet121  0.554981  0.756048    0.571259    0.731192   \n",
       "26      0          3    co-train1       NaN       NaN         NaN    0.729167   \n",
       "27      0          3    co-train2       NaN       NaN         NaN    0.731481   \n",
       "28      0          4     ResNet50  0.807665  0.702957    0.753912    0.719329   \n",
       "29      0          4     Xception  0.506234  0.752016    0.552964    0.708333   \n",
       "30      0          4  DenseNet169  0.621653  0.724462    0.596714    0.731771   \n",
       "31      0          4  InceptionV4  0.716354  0.740591    0.722031    0.748843   \n",
       "32      0          4  DenseNet121  0.605177  0.736559    0.606573    0.732639   \n",
       "33      0          4    co-train1       NaN       NaN         NaN    0.749132   \n",
       "34      0          4    co-train2       NaN       NaN         NaN    0.694734   \n",
       "\n",
       "    test1_precision  test1_recall  test1_f1score  test2_loss  test2_accu  \\\n",
       "0          0.717242      0.709491       0.702322    0.595368    0.700810   \n",
       "1          0.718921      0.718171       0.715732    0.590423    0.684028   \n",
       "2          0.692519      0.682292       0.671300    0.535179    0.716435   \n",
       "3          0.710778      0.708333       0.704251    0.566231    0.697338   \n",
       "4          0.753322      0.740451       0.733121    0.523628    0.753762   \n",
       "5          0.745126      0.735243       0.728735         NaN         NaN   \n",
       "6          0.775521      0.732350       0.746442         NaN         NaN   \n",
       "7          0.742586      0.730035       0.722122    0.532528    0.736979   \n",
       "8          0.713185      0.704861       0.704822    0.675446    0.611111   \n",
       "9          0.726861      0.717593       0.710229    0.544363    0.728009   \n",
       "10         0.737291      0.737558       0.737372    0.947563    0.692419   \n",
       "11         0.743096      0.726273       0.716413    0.512850    0.762731   \n",
       "12         0.748032      0.748264       0.747437         NaN         NaN   \n",
       "13         0.799070      0.707176       0.728125         NaN         NaN   \n",
       "14         0.734159      0.734375       0.733280    0.629182    0.686921   \n",
       "15         0.720946      0.720775       0.718938    0.581900    0.695891   \n",
       "16         0.739481      0.730324       0.723827    0.587720    0.750579   \n",
       "17         0.711992      0.711227       0.708553    0.593593    0.689815   \n",
       "18         0.737406      0.731771       0.726935    0.539941    0.747975   \n",
       "19         0.745195      0.742766       0.739942         NaN         NaN   \n",
       "20         0.792808      0.725405       0.743335         NaN         NaN   \n",
       "21         0.728127      0.725984       0.726360    0.949686    0.657697   \n",
       "22         0.694252      0.694155       0.694201    0.633485    0.639178   \n",
       "23         0.726705      0.711806       0.701425    0.514338    0.736111   \n",
       "24         0.736537      0.736400       0.736461    0.949705    0.679688   \n",
       "25         0.739877      0.731192       0.724949    0.568348    0.743924   \n",
       "26         0.734978      0.729167       0.724124         NaN         NaN   \n",
       "27         0.783652      0.731481       0.747151         NaN         NaN   \n",
       "28         0.721383      0.719329       0.715963    0.779337    0.706597   \n",
       "29         0.708813      0.708333       0.708512    0.643923    0.638310   \n",
       "30         0.731436      0.731771       0.730813    0.657055    0.709201   \n",
       "31         0.752431      0.748843       0.749188    1.028757    0.662616   \n",
       "32         0.742492      0.732639       0.725988    0.561124    0.747106   \n",
       "33         0.748795      0.749132       0.748528         NaN         NaN   \n",
       "34         0.791200      0.694734       0.716762         NaN         NaN   \n",
       "\n",
       "    test2_precision  test2_recall  test2_f1score  \n",
       "0          0.746138      0.700810       0.716534  \n",
       "1          0.759933      0.684028       0.705289  \n",
       "2          0.748557      0.716435       0.728526  \n",
       "3          0.760340      0.697338       0.716289  \n",
       "4          0.790647      0.753762       0.765838  \n",
       "5               NaN           NaN            NaN  \n",
       "6               NaN           NaN            NaN  \n",
       "7          0.773750      0.736979       0.749599  \n",
       "8          0.774817      0.611111       0.638468  \n",
       "9          0.769490      0.728009       0.741932  \n",
       "10         0.798457      0.692419       0.714944  \n",
       "11         0.790353      0.762731       0.772501  \n",
       "12              NaN           NaN            NaN  \n",
       "13              NaN           NaN            NaN  \n",
       "14         0.776595      0.686921       0.709126  \n",
       "15         0.776791      0.695891       0.716875  \n",
       "16         0.793094      0.750579       0.763829  \n",
       "17         0.763799      0.689815       0.710528  \n",
       "18         0.799916      0.747975       0.762821  \n",
       "19              NaN           NaN            NaN  \n",
       "20              NaN           NaN            NaN  \n",
       "21         0.790010      0.657697       0.682917  \n",
       "22         0.753503      0.639178       0.665756  \n",
       "23         0.765441      0.736111       0.746977  \n",
       "24         0.793434      0.679688       0.703292  \n",
       "25         0.788136      0.743924       0.757743  \n",
       "26              NaN           NaN            NaN  \n",
       "27              NaN           NaN            NaN  \n",
       "28         0.773067      0.706597       0.725494  \n",
       "29         0.757041      0.638310       0.665011  \n",
       "30         0.799798      0.709201       0.729945  \n",
       "31         0.803920      0.662616       0.687294  \n",
       "32         0.788805      0.747106       0.760349  \n",
       "33              NaN           NaN            NaN  \n",
       "34              NaN           NaN            NaN  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('/home/miguel/msc_testis_ssl_gleasson/exp_92/hardvard/logs/exp_92_train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet121\n",
      "\n",
      "\n",
      "\\multicolumn{1}{|l|}{DenseNet121} & 74.05 & 73.31 & 74.05 & 72.63 & 71.64 & 72.63 & 73.18 & 72.69 & 73.18 & 73.12 & 72.49 & 73.12 & 73.26 & 72.6 & 73.26 \\\\ \\hline\n",
      "\n",
      "\n",
      "DenseNet169\n",
      "\n",
      "\n",
      "\\multicolumn{1}{|l|}{DenseNet169} & 68.23 & 67.13 & 68.23 & 71.76 & 71.02 & 71.76 & 73.03 & 72.38 & 73.03 & 71.18 & 70.14 & 71.18 & 73.18 & 73.08 & 73.18 \\\\ \\hline\n",
      "\n",
      "\n",
      "InceptionV4\n",
      "\n",
      "\n",
      "\\multicolumn{1}{|l|}{InceptionV4} & 70.83 & 70.43 & 70.83 & 73.76 & 73.74 & 73.76 & 71.12 & 70.86 & 71.12 & 73.64 & 73.65 & 73.64 & 74.88 & 74.92 & 74.88 \\\\ \\hline\n",
      "\n",
      "\n",
      "ResNet50\n",
      "\n",
      "\n",
      "\\multicolumn{1}{|l|}{ResNet50} & 70.95 & 70.23 & 70.95 & 73.0 & 72.21 & 73.0 & 73.44 & 73.33 & 73.44 & 72.6 & 72.64 & 72.6 & 71.93 & 71.6 & 71.93 \\\\ \\hline\n",
      "\n",
      "\n",
      "Xception\n",
      "\n",
      "\n",
      "\\multicolumn{1}{|l|}{Xception} & 71.82 & 71.57 & 71.82 & 70.49 & 70.48 & 70.49 & 72.08 & 71.89 & 72.08 & 69.42 & 69.42 & 69.42 & 70.83 & 70.85 & 70.83 \\\\ \\hline\n",
      "\n",
      "\n",
      "co-train1\n",
      "\n",
      "\n",
      "\\multicolumn{1}{|l|}{co-train1} & 73.52 & 72.87 & 73.52 & 74.83 & 74.74 & 74.83 & 74.28 & 73.99 & 74.28 & 72.92 & 72.41 & 72.92 & 74.91 & 74.85 & 74.91 \\\\ \\hline\n",
      "\n",
      "\n",
      "co-train2\n",
      "\n",
      "\n",
      "\\multicolumn{1}{|l|}{co-train2} & 73.23 & 74.64 & 73.23 & 70.72 & 72.81 & 70.72 & 72.54 & 74.33 & 72.54 & 73.15 & 74.72 & 73.15 & 69.47 & 71.68 & 69.47 \\\\ \\hline\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = metrics_by_pathologist(1)\n",
    "df_pivoted = pivot_df(df, metrics)\n",
    "export_to_latex(df_pivoted, metrics, kfold_ok=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HARDVAR - PATHOLOGIST 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kfold</th>\n",
       "      <th>iteracion</th>\n",
       "      <th>arquitectura</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accu</th>\n",
       "      <th>test1_loss</th>\n",
       "      <th>test1_accu</th>\n",
       "      <th>test1_precision</th>\n",
       "      <th>test1_recall</th>\n",
       "      <th>test1_f1score</th>\n",
       "      <th>test2_loss</th>\n",
       "      <th>test2_accu</th>\n",
       "      <th>test2_precision</th>\n",
       "      <th>test2_recall</th>\n",
       "      <th>test2_f1score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>0.522397</td>\n",
       "      <td>0.730511</td>\n",
       "      <td>0.567843</td>\n",
       "      <td>0.709491</td>\n",
       "      <td>0.717242</td>\n",
       "      <td>0.709491</td>\n",
       "      <td>0.702322</td>\n",
       "      <td>0.595368</td>\n",
       "      <td>0.700810</td>\n",
       "      <td>0.746138</td>\n",
       "      <td>0.700810</td>\n",
       "      <td>0.716534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Xception</td>\n",
       "      <td>0.499213</td>\n",
       "      <td>0.756048</td>\n",
       "      <td>0.540164</td>\n",
       "      <td>0.718171</td>\n",
       "      <td>0.718921</td>\n",
       "      <td>0.718171</td>\n",
       "      <td>0.715732</td>\n",
       "      <td>0.590423</td>\n",
       "      <td>0.684028</td>\n",
       "      <td>0.759933</td>\n",
       "      <td>0.684028</td>\n",
       "      <td>0.705289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DenseNet169</td>\n",
       "      <td>0.559061</td>\n",
       "      <td>0.696909</td>\n",
       "      <td>0.580255</td>\n",
       "      <td>0.682292</td>\n",
       "      <td>0.692519</td>\n",
       "      <td>0.682292</td>\n",
       "      <td>0.671300</td>\n",
       "      <td>0.535179</td>\n",
       "      <td>0.716435</td>\n",
       "      <td>0.748557</td>\n",
       "      <td>0.716435</td>\n",
       "      <td>0.728526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>InceptionV4</td>\n",
       "      <td>0.526662</td>\n",
       "      <td>0.726479</td>\n",
       "      <td>0.559266</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.710778</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.704251</td>\n",
       "      <td>0.566231</td>\n",
       "      <td>0.697338</td>\n",
       "      <td>0.760340</td>\n",
       "      <td>0.697338</td>\n",
       "      <td>0.716289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DenseNet121</td>\n",
       "      <td>0.566669</td>\n",
       "      <td>0.744624</td>\n",
       "      <td>0.575830</td>\n",
       "      <td>0.740451</td>\n",
       "      <td>0.753322</td>\n",
       "      <td>0.740451</td>\n",
       "      <td>0.733121</td>\n",
       "      <td>0.523628</td>\n",
       "      <td>0.753762</td>\n",
       "      <td>0.790647</td>\n",
       "      <td>0.753762</td>\n",
       "      <td>0.765838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>co-train1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.735243</td>\n",
       "      <td>0.745126</td>\n",
       "      <td>0.735243</td>\n",
       "      <td>0.728735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>co-train2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732350</td>\n",
       "      <td>0.775521</td>\n",
       "      <td>0.732350</td>\n",
       "      <td>0.746442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>0.473966</td>\n",
       "      <td>0.769489</td>\n",
       "      <td>0.550157</td>\n",
       "      <td>0.730035</td>\n",
       "      <td>0.742586</td>\n",
       "      <td>0.730035</td>\n",
       "      <td>0.722122</td>\n",
       "      <td>0.532528</td>\n",
       "      <td>0.736979</td>\n",
       "      <td>0.773750</td>\n",
       "      <td>0.736979</td>\n",
       "      <td>0.749599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Xception</td>\n",
       "      <td>0.508900</td>\n",
       "      <td>0.751344</td>\n",
       "      <td>0.563566</td>\n",
       "      <td>0.704861</td>\n",
       "      <td>0.713185</td>\n",
       "      <td>0.704861</td>\n",
       "      <td>0.704822</td>\n",
       "      <td>0.675446</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.774817</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.638468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>DenseNet169</td>\n",
       "      <td>0.526339</td>\n",
       "      <td>0.717742</td>\n",
       "      <td>0.552728</td>\n",
       "      <td>0.717593</td>\n",
       "      <td>0.726861</td>\n",
       "      <td>0.717593</td>\n",
       "      <td>0.710229</td>\n",
       "      <td>0.544363</td>\n",
       "      <td>0.728009</td>\n",
       "      <td>0.769490</td>\n",
       "      <td>0.728009</td>\n",
       "      <td>0.741932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>InceptionV4</td>\n",
       "      <td>0.748703</td>\n",
       "      <td>0.733199</td>\n",
       "      <td>0.747231</td>\n",
       "      <td>0.737558</td>\n",
       "      <td>0.737291</td>\n",
       "      <td>0.737558</td>\n",
       "      <td>0.737372</td>\n",
       "      <td>0.947563</td>\n",
       "      <td>0.692419</td>\n",
       "      <td>0.798457</td>\n",
       "      <td>0.692419</td>\n",
       "      <td>0.714944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>DenseNet121</td>\n",
       "      <td>0.628504</td>\n",
       "      <td>0.727823</td>\n",
       "      <td>0.623558</td>\n",
       "      <td>0.726273</td>\n",
       "      <td>0.743096</td>\n",
       "      <td>0.726273</td>\n",
       "      <td>0.716413</td>\n",
       "      <td>0.512850</td>\n",
       "      <td>0.762731</td>\n",
       "      <td>0.790353</td>\n",
       "      <td>0.762731</td>\n",
       "      <td>0.772501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>co-train1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.748264</td>\n",
       "      <td>0.748032</td>\n",
       "      <td>0.748264</td>\n",
       "      <td>0.747437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>co-train2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.707176</td>\n",
       "      <td>0.799070</td>\n",
       "      <td>0.707176</td>\n",
       "      <td>0.728125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>0.494110</td>\n",
       "      <td>0.741263</td>\n",
       "      <td>0.525381</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.734159</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.733280</td>\n",
       "      <td>0.629182</td>\n",
       "      <td>0.686921</td>\n",
       "      <td>0.776595</td>\n",
       "      <td>0.686921</td>\n",
       "      <td>0.709126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Xception</td>\n",
       "      <td>0.508038</td>\n",
       "      <td>0.743280</td>\n",
       "      <td>0.541066</td>\n",
       "      <td>0.720775</td>\n",
       "      <td>0.720946</td>\n",
       "      <td>0.720775</td>\n",
       "      <td>0.718938</td>\n",
       "      <td>0.581900</td>\n",
       "      <td>0.695891</td>\n",
       "      <td>0.776791</td>\n",
       "      <td>0.695891</td>\n",
       "      <td>0.716875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>DenseNet169</td>\n",
       "      <td>0.720527</td>\n",
       "      <td>0.698253</td>\n",
       "      <td>0.653575</td>\n",
       "      <td>0.730324</td>\n",
       "      <td>0.739481</td>\n",
       "      <td>0.730324</td>\n",
       "      <td>0.723827</td>\n",
       "      <td>0.587720</td>\n",
       "      <td>0.750579</td>\n",
       "      <td>0.793094</td>\n",
       "      <td>0.750579</td>\n",
       "      <td>0.763829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>InceptionV4</td>\n",
       "      <td>0.556849</td>\n",
       "      <td>0.717070</td>\n",
       "      <td>0.569146</td>\n",
       "      <td>0.711227</td>\n",
       "      <td>0.711992</td>\n",
       "      <td>0.711227</td>\n",
       "      <td>0.708553</td>\n",
       "      <td>0.593593</td>\n",
       "      <td>0.689815</td>\n",
       "      <td>0.763799</td>\n",
       "      <td>0.689815</td>\n",
       "      <td>0.710528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>DenseNet121</td>\n",
       "      <td>0.577595</td>\n",
       "      <td>0.746640</td>\n",
       "      <td>0.595283</td>\n",
       "      <td>0.731771</td>\n",
       "      <td>0.737406</td>\n",
       "      <td>0.731771</td>\n",
       "      <td>0.726935</td>\n",
       "      <td>0.539941</td>\n",
       "      <td>0.747975</td>\n",
       "      <td>0.799916</td>\n",
       "      <td>0.747975</td>\n",
       "      <td>0.762821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>co-train1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742766</td>\n",
       "      <td>0.745195</td>\n",
       "      <td>0.742766</td>\n",
       "      <td>0.739942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>co-train2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725405</td>\n",
       "      <td>0.792808</td>\n",
       "      <td>0.725405</td>\n",
       "      <td>0.743335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>0.754385</td>\n",
       "      <td>0.710349</td>\n",
       "      <td>0.696673</td>\n",
       "      <td>0.725984</td>\n",
       "      <td>0.728127</td>\n",
       "      <td>0.725984</td>\n",
       "      <td>0.726360</td>\n",
       "      <td>0.949686</td>\n",
       "      <td>0.657697</td>\n",
       "      <td>0.790010</td>\n",
       "      <td>0.657697</td>\n",
       "      <td>0.682917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Xception</td>\n",
       "      <td>0.543845</td>\n",
       "      <td>0.718414</td>\n",
       "      <td>0.568819</td>\n",
       "      <td>0.694155</td>\n",
       "      <td>0.694252</td>\n",
       "      <td>0.694155</td>\n",
       "      <td>0.694201</td>\n",
       "      <td>0.633485</td>\n",
       "      <td>0.639178</td>\n",
       "      <td>0.753503</td>\n",
       "      <td>0.639178</td>\n",
       "      <td>0.665756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>DenseNet169</td>\n",
       "      <td>0.554147</td>\n",
       "      <td>0.728495</td>\n",
       "      <td>0.574311</td>\n",
       "      <td>0.711806</td>\n",
       "      <td>0.726705</td>\n",
       "      <td>0.711806</td>\n",
       "      <td>0.701425</td>\n",
       "      <td>0.514338</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.765441</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.746977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>InceptionV4</td>\n",
       "      <td>0.759834</td>\n",
       "      <td>0.715726</td>\n",
       "      <td>0.701141</td>\n",
       "      <td>0.736400</td>\n",
       "      <td>0.736537</td>\n",
       "      <td>0.736400</td>\n",
       "      <td>0.736461</td>\n",
       "      <td>0.949705</td>\n",
       "      <td>0.679688</td>\n",
       "      <td>0.793434</td>\n",
       "      <td>0.679688</td>\n",
       "      <td>0.703292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>DenseNet121</td>\n",
       "      <td>0.554981</td>\n",
       "      <td>0.756048</td>\n",
       "      <td>0.571259</td>\n",
       "      <td>0.731192</td>\n",
       "      <td>0.739877</td>\n",
       "      <td>0.731192</td>\n",
       "      <td>0.724949</td>\n",
       "      <td>0.568348</td>\n",
       "      <td>0.743924</td>\n",
       "      <td>0.788136</td>\n",
       "      <td>0.743924</td>\n",
       "      <td>0.757743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>co-train1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.734978</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.724124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>co-train2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731481</td>\n",
       "      <td>0.783652</td>\n",
       "      <td>0.731481</td>\n",
       "      <td>0.747151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>0.807665</td>\n",
       "      <td>0.702957</td>\n",
       "      <td>0.753912</td>\n",
       "      <td>0.719329</td>\n",
       "      <td>0.721383</td>\n",
       "      <td>0.719329</td>\n",
       "      <td>0.715963</td>\n",
       "      <td>0.779337</td>\n",
       "      <td>0.706597</td>\n",
       "      <td>0.773067</td>\n",
       "      <td>0.706597</td>\n",
       "      <td>0.725494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Xception</td>\n",
       "      <td>0.506234</td>\n",
       "      <td>0.752016</td>\n",
       "      <td>0.552964</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708813</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708512</td>\n",
       "      <td>0.643923</td>\n",
       "      <td>0.638310</td>\n",
       "      <td>0.757041</td>\n",
       "      <td>0.638310</td>\n",
       "      <td>0.665011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>DenseNet169</td>\n",
       "      <td>0.621653</td>\n",
       "      <td>0.724462</td>\n",
       "      <td>0.596714</td>\n",
       "      <td>0.731771</td>\n",
       "      <td>0.731436</td>\n",
       "      <td>0.731771</td>\n",
       "      <td>0.730813</td>\n",
       "      <td>0.657055</td>\n",
       "      <td>0.709201</td>\n",
       "      <td>0.799798</td>\n",
       "      <td>0.709201</td>\n",
       "      <td>0.729945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>InceptionV4</td>\n",
       "      <td>0.716354</td>\n",
       "      <td>0.740591</td>\n",
       "      <td>0.722031</td>\n",
       "      <td>0.748843</td>\n",
       "      <td>0.752431</td>\n",
       "      <td>0.748843</td>\n",
       "      <td>0.749188</td>\n",
       "      <td>1.028757</td>\n",
       "      <td>0.662616</td>\n",
       "      <td>0.803920</td>\n",
       "      <td>0.662616</td>\n",
       "      <td>0.687294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>DenseNet121</td>\n",
       "      <td>0.605177</td>\n",
       "      <td>0.736559</td>\n",
       "      <td>0.606573</td>\n",
       "      <td>0.732639</td>\n",
       "      <td>0.742492</td>\n",
       "      <td>0.732639</td>\n",
       "      <td>0.725988</td>\n",
       "      <td>0.561124</td>\n",
       "      <td>0.747106</td>\n",
       "      <td>0.788805</td>\n",
       "      <td>0.747106</td>\n",
       "      <td>0.760349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>co-train1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.749132</td>\n",
       "      <td>0.748795</td>\n",
       "      <td>0.749132</td>\n",
       "      <td>0.748528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>co-train2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.694734</td>\n",
       "      <td>0.791200</td>\n",
       "      <td>0.694734</td>\n",
       "      <td>0.716762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    kfold  iteracion arquitectura  val_loss  val_accu  test1_loss  test1_accu  \\\n",
       "0       0          0     ResNet50  0.522397  0.730511    0.567843    0.709491   \n",
       "1       0          0     Xception  0.499213  0.756048    0.540164    0.718171   \n",
       "2       0          0  DenseNet169  0.559061  0.696909    0.580255    0.682292   \n",
       "3       0          0  InceptionV4  0.526662  0.726479    0.559266    0.708333   \n",
       "4       0          0  DenseNet121  0.566669  0.744624    0.575830    0.740451   \n",
       "5       0          0    co-train1       NaN       NaN         NaN    0.735243   \n",
       "6       0          0    co-train2       NaN       NaN         NaN    0.732350   \n",
       "7       0          1     ResNet50  0.473966  0.769489    0.550157    0.730035   \n",
       "8       0          1     Xception  0.508900  0.751344    0.563566    0.704861   \n",
       "9       0          1  DenseNet169  0.526339  0.717742    0.552728    0.717593   \n",
       "10      0          1  InceptionV4  0.748703  0.733199    0.747231    0.737558   \n",
       "11      0          1  DenseNet121  0.628504  0.727823    0.623558    0.726273   \n",
       "12      0          1    co-train1       NaN       NaN         NaN    0.748264   \n",
       "13      0          1    co-train2       NaN       NaN         NaN    0.707176   \n",
       "14      0          2     ResNet50  0.494110  0.741263    0.525381    0.734375   \n",
       "15      0          2     Xception  0.508038  0.743280    0.541066    0.720775   \n",
       "16      0          2  DenseNet169  0.720527  0.698253    0.653575    0.730324   \n",
       "17      0          2  InceptionV4  0.556849  0.717070    0.569146    0.711227   \n",
       "18      0          2  DenseNet121  0.577595  0.746640    0.595283    0.731771   \n",
       "19      0          2    co-train1       NaN       NaN         NaN    0.742766   \n",
       "20      0          2    co-train2       NaN       NaN         NaN    0.725405   \n",
       "21      0          3     ResNet50  0.754385  0.710349    0.696673    0.725984   \n",
       "22      0          3     Xception  0.543845  0.718414    0.568819    0.694155   \n",
       "23      0          3  DenseNet169  0.554147  0.728495    0.574311    0.711806   \n",
       "24      0          3  InceptionV4  0.759834  0.715726    0.701141    0.736400   \n",
       "25      0          3  DenseNet121  0.554981  0.756048    0.571259    0.731192   \n",
       "26      0          3    co-train1       NaN       NaN         NaN    0.729167   \n",
       "27      0          3    co-train2       NaN       NaN         NaN    0.731481   \n",
       "28      0          4     ResNet50  0.807665  0.702957    0.753912    0.719329   \n",
       "29      0          4     Xception  0.506234  0.752016    0.552964    0.708333   \n",
       "30      0          4  DenseNet169  0.621653  0.724462    0.596714    0.731771   \n",
       "31      0          4  InceptionV4  0.716354  0.740591    0.722031    0.748843   \n",
       "32      0          4  DenseNet121  0.605177  0.736559    0.606573    0.732639   \n",
       "33      0          4    co-train1       NaN       NaN         NaN    0.749132   \n",
       "34      0          4    co-train2       NaN       NaN         NaN    0.694734   \n",
       "\n",
       "    test1_precision  test1_recall  test1_f1score  test2_loss  test2_accu  \\\n",
       "0          0.717242      0.709491       0.702322    0.595368    0.700810   \n",
       "1          0.718921      0.718171       0.715732    0.590423    0.684028   \n",
       "2          0.692519      0.682292       0.671300    0.535179    0.716435   \n",
       "3          0.710778      0.708333       0.704251    0.566231    0.697338   \n",
       "4          0.753322      0.740451       0.733121    0.523628    0.753762   \n",
       "5          0.745126      0.735243       0.728735         NaN         NaN   \n",
       "6          0.775521      0.732350       0.746442         NaN         NaN   \n",
       "7          0.742586      0.730035       0.722122    0.532528    0.736979   \n",
       "8          0.713185      0.704861       0.704822    0.675446    0.611111   \n",
       "9          0.726861      0.717593       0.710229    0.544363    0.728009   \n",
       "10         0.737291      0.737558       0.737372    0.947563    0.692419   \n",
       "11         0.743096      0.726273       0.716413    0.512850    0.762731   \n",
       "12         0.748032      0.748264       0.747437         NaN         NaN   \n",
       "13         0.799070      0.707176       0.728125         NaN         NaN   \n",
       "14         0.734159      0.734375       0.733280    0.629182    0.686921   \n",
       "15         0.720946      0.720775       0.718938    0.581900    0.695891   \n",
       "16         0.739481      0.730324       0.723827    0.587720    0.750579   \n",
       "17         0.711992      0.711227       0.708553    0.593593    0.689815   \n",
       "18         0.737406      0.731771       0.726935    0.539941    0.747975   \n",
       "19         0.745195      0.742766       0.739942         NaN         NaN   \n",
       "20         0.792808      0.725405       0.743335         NaN         NaN   \n",
       "21         0.728127      0.725984       0.726360    0.949686    0.657697   \n",
       "22         0.694252      0.694155       0.694201    0.633485    0.639178   \n",
       "23         0.726705      0.711806       0.701425    0.514338    0.736111   \n",
       "24         0.736537      0.736400       0.736461    0.949705    0.679688   \n",
       "25         0.739877      0.731192       0.724949    0.568348    0.743924   \n",
       "26         0.734978      0.729167       0.724124         NaN         NaN   \n",
       "27         0.783652      0.731481       0.747151         NaN         NaN   \n",
       "28         0.721383      0.719329       0.715963    0.779337    0.706597   \n",
       "29         0.708813      0.708333       0.708512    0.643923    0.638310   \n",
       "30         0.731436      0.731771       0.730813    0.657055    0.709201   \n",
       "31         0.752431      0.748843       0.749188    1.028757    0.662616   \n",
       "32         0.742492      0.732639       0.725988    0.561124    0.747106   \n",
       "33         0.748795      0.749132       0.748528         NaN         NaN   \n",
       "34         0.791200      0.694734       0.716762         NaN         NaN   \n",
       "\n",
       "    test2_precision  test2_recall  test2_f1score  \n",
       "0          0.746138      0.700810       0.716534  \n",
       "1          0.759933      0.684028       0.705289  \n",
       "2          0.748557      0.716435       0.728526  \n",
       "3          0.760340      0.697338       0.716289  \n",
       "4          0.790647      0.753762       0.765838  \n",
       "5               NaN           NaN            NaN  \n",
       "6               NaN           NaN            NaN  \n",
       "7          0.773750      0.736979       0.749599  \n",
       "8          0.774817      0.611111       0.638468  \n",
       "9          0.769490      0.728009       0.741932  \n",
       "10         0.798457      0.692419       0.714944  \n",
       "11         0.790353      0.762731       0.772501  \n",
       "12              NaN           NaN            NaN  \n",
       "13              NaN           NaN            NaN  \n",
       "14         0.776595      0.686921       0.709126  \n",
       "15         0.776791      0.695891       0.716875  \n",
       "16         0.793094      0.750579       0.763829  \n",
       "17         0.763799      0.689815       0.710528  \n",
       "18         0.799916      0.747975       0.762821  \n",
       "19              NaN           NaN            NaN  \n",
       "20              NaN           NaN            NaN  \n",
       "21         0.790010      0.657697       0.682917  \n",
       "22         0.753503      0.639178       0.665756  \n",
       "23         0.765441      0.736111       0.746977  \n",
       "24         0.793434      0.679688       0.703292  \n",
       "25         0.788136      0.743924       0.757743  \n",
       "26              NaN           NaN            NaN  \n",
       "27              NaN           NaN            NaN  \n",
       "28         0.773067      0.706597       0.725494  \n",
       "29         0.757041      0.638310       0.665011  \n",
       "30         0.799798      0.709201       0.729945  \n",
       "31         0.803920      0.662616       0.687294  \n",
       "32         0.788805      0.747106       0.760349  \n",
       "33              NaN           NaN            NaN  \n",
       "34              NaN           NaN            NaN  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('/home/miguel/msc_testis_ssl_gleasson/exp_92/hardvard/logs/exp_92_train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet121\n",
      "\n",
      "\n",
      "\\multicolumn{1}{|l|}{DenseNet121} & 75.38 & 76.58 & 75.38 & 76.27 & 77.25 & 76.27 & 74.8 & 76.28 & 74.8 & 74.39 & 75.77 & 74.39 & 74.71 & 76.03 & 74.71 \\\\ \\hline\n",
      "\n",
      "\n",
      "DenseNet169\n",
      "\n",
      "\n",
      "\\multicolumn{1}{|l|}{DenseNet169} & 71.64 & 72.85 & 71.64 & 72.8 & 74.19 & 72.8 & 75.06 & 76.38 & 75.06 & 73.61 & 74.7 & 73.61 & 70.92 & 72.99 & 70.92 \\\\ \\hline\n",
      "\n",
      "\n",
      "InceptionV4\n",
      "\n",
      "\n",
      "\\multicolumn{1}{|l|}{InceptionV4} & 69.73 & 71.63 & 69.73 & 69.24 & 71.49 & 69.24 & 68.98 & 71.05 & 68.98 & 67.97 & 70.33 & 67.97 & 66.26 & 68.73 & 66.26 \\\\ \\hline\n",
      "\n",
      "\n",
      "ResNet50\n",
      "\n",
      "\n",
      "\\multicolumn{1}{|l|}{ResNet50} & 70.08 & 71.65 & 70.08 & 73.7 & 74.96 & 73.7 & 68.69 & 70.91 & 68.69 & 65.77 & 68.29 & 65.77 & 70.66 & 72.55 & 70.66 \\\\ \\hline\n",
      "\n",
      "\n",
      "Xception\n",
      "\n",
      "\n",
      "\\multicolumn{1}{|l|}{Xception} & 68.4 & 70.53 & 68.4 & 61.11 & 63.85 & 61.11 & 69.59 & 71.69 & 69.59 & 63.92 & 66.58 & 63.92 & 63.83 & 66.5 & 63.83 \\\\ \\hline\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = metrics_by_pathologist(2)\n",
    "df_pivoted = pivot_df(df, metrics)\n",
    "export_to_latex(df_pivoted, metrics, kfold_ok=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
